{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f172f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32dd507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n=====MBTI Training Dataset INSPECTION=====\n",
      "Shape: (18861, 2)\n",
      "Columns: Index(['type', 'posts'], dtype='object')\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18861 entries, 0 to 18860\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    18861 non-null  object\n",
      " 1   posts   18861 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 294.8+ KB\n",
      "None\n",
      "\n",
      "Head:\n",
      "        type                                              posts\n",
      "0  <UNKNOWN>  BBC|||I only have a social software like Weibo...\n",
      "1  <UNKNOWN>  # Yang Yang is the first love #|||This is fun|...\n",
      "2  <UNKNOWN>  I've just taken a video of the video|||those w...\n",
      "3  <UNKNOWN>  I've just given a flower to Zhong Han-Lian, an...\n",
      "4  <UNKNOWN>  Zenium|||If you don't, you don't have long hai...\n",
      "\n",
      "Missing Values per Column:\n",
      "type     0\n",
      "posts    0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:(numeric columns):\n",
      "             type  posts\n",
      "count       18861  18861\n",
      "unique          1  16728\n",
      "top     <UNKNOWN>      /\n",
      "freq        18861    364\n",
      "\n",
      "Outlier Check (based on IQR, numeric columns):\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "training = pd.read_excel(\"dataset/mbti_training_dataset.xlsx\")\n",
    "\n",
    "###TASK 1: Dataset Inspection###\n",
    "#inspecting the datasets\n",
    "def inspect_dataset(df,name=\"Dataset\"):\n",
    "  print(f\"/n====={name} INSPECTION=====\")\n",
    "\n",
    "#looking through shape and info about the datasets\n",
    "  print(f\"Shape: {df.shape}\")\n",
    "  print(f\"Columns: {df.columns}\")\n",
    "  print(\"Info:\")\n",
    "  print(df.info())\n",
    "\n",
    "  print(\"\\nHead:\")\n",
    "  print(df.head())\n",
    "#missing values\n",
    "  print(\"\\nMissing Values per Column:\")\n",
    "  print(df.isnull().sum())\n",
    "\n",
    "#summary statistics\n",
    "  print(\"\\nSummary Statistics:(numeric columns):\")\n",
    "  print(df.describe())\n",
    "\n",
    "  #for checking outliers\n",
    "  print(\"\\nOutlier Check (based on IQR, numeric columns):\")\n",
    "  numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "  for col in numeric_cols:\n",
    "      q1 = df[col].quantile(0.25)\n",
    "      q3 = df[col].quantile(0.75)\n",
    "      iqr = q3 - q1\n",
    "\n",
    "      outliers = df[(df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))]\n",
    "      print(f\"{col}: {len(outliers)} potential outliers\")\n",
    "\n",
    "  print(\"=\"*50)\n",
    "\n",
    "# Inspecting all the datasets\n",
    "inspect_dataset(training, \"MBTI Training Dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c380a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "      <td>BBC|||I only have a social software like Weibo...</td>\n",
       "      <td>bbci social software like weibo ive recently i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "      <td># Yang Yang is the first love #|||This is fun|...</td>\n",
       "      <td>yang yang love funi shared whats aboutpoison i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "      <td>I've just taken a video of the video|||those w...</td>\n",
       "      <td>ive just taken video videothose rebut microblo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "      <td>I've just given a flower to Zhong Han-Lian, an...</td>\n",
       "      <td>ive just given flower zhong hanlian ive earned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;UNKNOWN&gt;</td>\n",
       "      <td>Zenium|||If you don't, you don't have long hai...</td>\n",
       "      <td>zeniumif dont dont long hair right humming whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts  \\\n",
       "0  <UNKNOWN>  BBC|||I only have a social software like Weibo...   \n",
       "1  <UNKNOWN>  # Yang Yang is the first love #|||This is fun|...   \n",
       "2  <UNKNOWN>  I've just taken a video of the video|||those w...   \n",
       "3  <UNKNOWN>  I've just given a flower to Zhong Han-Lian, an...   \n",
       "4  <UNKNOWN>  Zenium|||If you don't, you don't have long hai...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  bbci social software like weibo ive recently i...  \n",
       "1  yang yang love funi shared whats aboutpoison i...  \n",
       "2  ive just taken video videothose rebut microblo...  \n",
       "3  ive just given flower zhong hanlian ive earned...  \n",
       "4  zeniumif dont dont long hair right humming whi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TASK 2: Clean data, remove stopwords and tokenize text ###\n",
    "# Prepare stop words (combine sklearn's stop words with NLTK's if available)\n",
    "\n",
    "stop_words = set(ENGLISH_STOP_WORDS)\n",
    "try:\n",
    "    from nltk.corpus import stopwords as nltk_stop\n",
    "    stop_words = stop_words.union(set(nltk_stop.words('english')))\n",
    "except Exception:\n",
    "    # NLTK stopwords may not be downloaded in this environment; it's ok to proceed\n",
    "    pass\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "training['cleaned_text'] = training.get('posts', '') .apply(clean_text) if 'posts' in training.columns else ''\n",
    "\n",
    "# TF-IDF vectorizer (only run if cleaned text present)\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=5)\n",
    "if 'cleaned_text' in training.columns and training['cleaned_text'].astype(bool).any():\n",
    "    X = vectorizer.fit_transform(training['cleaned_text'])\n",
    "    y = training['type'] if 'type' in training.columns else None\n",
    "else:\n",
    "    X = None\n",
    "    y = None\n",
    "\n",
    "training.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
